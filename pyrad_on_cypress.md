###Intro to Cypress

All the information you ever needed, including setting up an account, can be found here
https://wiki.hpc.tulane.edu/trac/wiki/cypress#CodingonCypress

* Please make sure you have reviwed the cypress wiki before Thursday and in particular, how to submit job requests (https://wiki.hpc.tulane.edu/trac/wiki/cypress/using#SubmittingJobsonCypress)

Once your account is set up, logging in is easy. Replace "eenbody" with your Tulane username and then type your Tulane password when prompted.

```bash
ssh eenbody@cypress1.tulane.edu
```

###pyRAD Tutorial on cypress

Now we can run the pyRAD tutorial on the cluster (http://nbviewer.jupyter.org/gist/dereneaton/1f661bfb205b644086cc/tutorial_RAD_3.0.ipynb)

* Open a new terminal window (not on cypress) and download the pyRAD RAD tutorial data into your current directory

```bash
wget -q dereneaton.com/downloads/simRADs.zip
unzip simRADs.zip
```

* Next, we're going to copy the folder over to your directory on cypress. Just replace eenbody with your username.

```bash
scp ./simRADs/ eenbody@cypress1.tulane.edu:/home/eenbody
```

* Either log into cypress or return to the window where you had cypress open. 
* Navigate into the simRADs directory. 
* Create a new job ticket file

```bash
nano pyrad_n.srun
```

* The contents should be this (make sure you understand what each line means, via the wiki above). pyRAD is already installed as a module on cypress and to run it you must load it in (module load pyrad) and execute it using pyrad (lowercase). 

```bash

#!/bin/bash
#SBATCH --job-name=OneHourJob ### Job Name
#SBATCH --nodes=1             ### Node count required for the job
#SBATCH --ntasks-per-node=1   ### Nuber of tasks to be launched per Node

module load pyrad

pyrad -n
```

* Execute the command using sbatch

```bash
sbatch pyrad_n.srun
```

* Just like running this on your desktop, if this ran successfully, you should have a params.txt file in your directory.

* On cypress, you should have no issues editing the params.txt file using sed

```bash
%%bash
sed -i '/## 7. /c\2                   ## 7. N processors... ' params.txt
sed -i '/## 10. /c\.85                ## 10. lowered clust thresh... ' params.txt
sed -i '/## 14. /c\c85m4p3            ## 14. outprefix... ' params.txt
sed -i '/## 24./c\8                   ## 24. maxH raised ... ' params.txt
sed -i '/## 30./c\*                   ## 30. all output formats... ' params.txt
```

* Now, create a new job request file called pyrad1.srun with the following info, then run it with sbatch. You should be able to do the same with all 7 steps of the RAD tutorial. 

```bash
#!/bin/bash
#SBATCH --job-name=OneHourJob ### Job Name
#SBATCH --nodes=1             ### Node count required for the job
#SBATCH --ntasks-per-node=1   ### Nuber of tasks to be launched per Node

module load pyrad

pyrad -p params.txt -s 1
```

####Running pyRAD with a real dataset

We are going to use pyRAD to call SNPs on Sara L's dataset from her work with jacana. These are data generated by a slightly different method than that above, as her samples were sequenced by genoytpe by sequencing (GBS) methods. As far as pyRAD is concerned, things won't change that much. 

* First, you will need to copy the raw data to your lab's project folder. Only one member per lab should do this. You will also need to physically go to the derryberry lab to initiate this transfer. I will send instructions by email about the password.

* Once you are at the computer, open terminal and login to cypress. You want to find your way to the lustre project folder for your lab and make a directory for jacanas. For example for the karubian lab see below. You should only have permission to access your workgroup's folder.

```bash
cd /lustre/project/jk
mkdir Jacana_Raw_Reads
```

* Now that we are here, lets transfer those files. They are large files and total ~60gb, so using the "scp" command is a bit unwieldy as it was built for smaller files. Instead we will use bcbp

```bash
bbcp -zv -r "/Volumes/LaCie/Jacana GBS Raw Reads" Jacana_Raw_Reads/
```

-v stands for verbose 
-r is for recursive (copies all files in the directory)
-z I am not so sure about (Graham?) if this isn't working for you, maybe take this out.

You should get some output like this (each line comes in slowly)

```bash
bbcp: Indexing files to be copied...
bbcp: Copying 5 files and 0 links in 1 directory.
File Jacana_Raw_Reads/Jacana GBS Raw Reads/.DS_Store created; 6148 bytes at 255.8 KB/s
File Jacana_Raw_Reads/Jacana GBS Raw Reads/C6RL0ANXX_1_fastq created; 67982686805 bytes at 76.8 MB/s
File Jacana_Raw_Reads/Jacana GBS Raw Reads/C6RL0ANXX_1_fastq.gz created; 18058122029 bytes at 67.9 MB/s
File Jacana_Raw_Reads/Jacana GBS Raw Reads/C6RL0ANXX_2_fastq.gz created; 17324891025 bytes at 67.2 MB/s
File Jacana_Raw_Reads/Jacana GBS Raw Reads/C6RL0ANXX_3_fastq.gz created; 17453590465 bytes at 64.3 MB/s
5 files copied at effectively 71.7 MB/s\
```

I'm not sure how long mine took, but at least half an hour I think. Now you are ready to use cypress to dig through this dataset!




